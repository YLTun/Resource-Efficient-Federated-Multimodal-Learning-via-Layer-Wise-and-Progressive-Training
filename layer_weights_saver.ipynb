{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4a4803-b83e-405e-bde7-b2858b2fe120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "gpu_index = '0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_index\n",
    "os.environ['HF_HOME'] = '../huggingface_cache/'      # Cache directory for huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b19a166-a2d8-43c1-aeb7-193fff2d8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d1651e-4870-4924-a76a-d93972a9d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d84f54-062c-49c1-9cb8-7eed7524b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './pretrained_weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb35e3a-0b59-4b0d-a618-bb3be7794246",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43effcef-c14e-4f9f-902a-e4d548142309",
   "metadata": {},
   "source": [
    "### vit-tiny-patch16-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca2111b-e426-40df-9e54-6b1d2458d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTModel\n",
    "from transformers.models.vit.modeling_vit import ViTLayer\n",
    "\n",
    "vit_enc_name = 'WinKawaks/vit-tiny-patch16-224'\n",
    "vit_enc = ViTModel.from_pretrained(vit_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7048175-5fa2-4565-9a93-6ddb0fe490c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/vit-tiny-patch16-224'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_weight_dir = os.path.join(base_dir, vit_enc_name.split('/')[-1])\n",
    "os.makedirs(vit_weight_dir, exist_ok=True)\n",
    "vit_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72108ad1-dcbf-48e9-af07-c05209e33fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTModel(\n",
       "  (embeddings): ViTEmbeddings(\n",
       "    (patch_embeddings): ViTPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ViTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ViTLayer(\n",
       "        (attention): ViTSdpaAttention(\n",
       "          (attention): ViTSdpaSelfAttention(\n",
       "            (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (key): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTSelfOutput(\n",
       "            (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTIntermediate(\n",
       "          (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTOutput(\n",
       "          (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
       "  (pooler): ViTPooler(\n",
       "    (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_enc = vit_enc.to(device)\n",
    "vit_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230914b4-7017-4cc9-bdee-50c6352a7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(vit_enc.embeddings.state_dict(), os.path.join(vit_weight_dir, 'vit_embeddings.pth'))\n",
    "\n",
    "for idx, layer in enumerate(vit_enc.encoder.layer):\n",
    "    torch.save(layer.state_dict(), os.path.join(vit_weight_dir, 'vit_layer_{}.pth'.format(idx)))\n",
    "\n",
    "torch.save(vit_enc.layernorm.state_dict(), os.path.join(vit_weight_dir, 'vit_layernorm.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ec9006-d2af-49e3-a706-d375a29ca30b",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472b7c0-1a82-4da0-be73-157913aaa158",
   "metadata": {},
   "source": [
    "### microsoft/resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "570caf95-51d5-4f82-8032-034f9648136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ResNetModel\n",
    "\n",
    "resnet18_enc_name = 'microsoft/resnet-18'\n",
    "resnet18_enc = ResNetModel.from_pretrained(resnet18_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19f39486-3e05-49b9-a89e-0cf9d2e5cc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/resnet-18'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_weight_dir = os.path.join(base_dir, resnet18_enc_name.split('/')[-1])\n",
    "os.makedirs(resnet18_weight_dir, exist_ok=True)\n",
    "resnet18_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b606207-88cf-4f91-95e2-507fa30f2bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetModel(\n",
       "  (embedder): ResNetEmbeddings(\n",
       "    (embedder): ResNetConvLayer(\n",
       "      (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder): ResNetEncoder(\n",
       "    (stages): ModuleList(\n",
       "      (0): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBasicLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBasicLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBasicLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_enc = resnet18_enc.to(device)\n",
    "resnet18_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbb9afe8-2d01-4461-8993-e1b029c0cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(resnet18_enc.embedder.state_dict(), os.path.join(resnet18_weight_dir, 'embedder.pth'))\n",
    "\n",
    "for idx, layer in enumerate(resnet18_enc.encoder.stages):\n",
    "    torch.save(layer.state_dict(), os.path.join(resnet18_weight_dir, 'stage_{}.pth'.format(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03bcd54-06d8-44d1-b613-cba89298bcc7",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c1460-b121-45c8-ad43-a34e6e154226",
   "metadata": {},
   "source": [
    "### microsoft/resnet-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f44e7d-75fa-4579-9d31-d6813dbd5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ResNetModel\n",
    "\n",
    "resnet34_enc_name = 'microsoft/resnet-34'\n",
    "resnet34_enc = ResNetModel.from_pretrained(resnet34_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bf0ef86-59b5-4c12-95f0-4fdbd7e4fd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/resnet-34'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet34_weight_dir = os.path.join(base_dir, resnet34_enc_name.split('/')[-1])\n",
    "os.makedirs(resnet34_weight_dir, exist_ok=True)\n",
    "resnet34_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd71ec9-5149-4dcb-aab5-76df0b795347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetModel(\n",
       "  (embedder): ResNetEmbeddings(\n",
       "    (embedder): ResNetConvLayer(\n",
       "      (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder): ResNetEncoder(\n",
       "    (stages): ModuleList(\n",
       "      (0): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (2): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBasicLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (2): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (3): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBasicLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (2): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (3): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (4): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (5): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResNetStage(\n",
       "        (layers): Sequential(\n",
       "          (0): ResNetBasicLayer(\n",
       "            (shortcut): ResNetShortCut(\n",
       "              (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (1): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (2): ResNetBasicLayer(\n",
       "            (shortcut): Identity()\n",
       "            (layer): Sequential(\n",
       "              (0): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): ReLU()\n",
       "              )\n",
       "              (1): ResNetConvLayer(\n",
       "                (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet34_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3698110f-5aee-4a87-841e-ef7c321cb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(resnet34_enc.embedder.state_dict(), os.path.join(resnet34_weight_dir, 'embedder.pth'))\n",
    "\n",
    "for idx, layer in enumerate(resnet34_enc.encoder.stages):\n",
    "    torch.save(layer.state_dict(), os.path.join(resnet34_weight_dir, 'stage_{}.pth'.format(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686b5ce-6d01-4c30-97b4-81afe3b056b9",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18920cf-66d1-41a2-a5d9-0da6e908a686",
   "metadata": {},
   "source": [
    "### distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb1813ef-27ba-4435-a752-f884b83782f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers.models.distilbert.modeling_distilbert import TransformerBlock\n",
    "\n",
    "distilbert_enc_name = 'distilbert-base-uncased'\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(distilbert_enc_name)\n",
    "distilbert_enc = DistilBertModel.from_pretrained(distilbert_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ed5ca50-e558-4817-8fec-2a275d8e33cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/distilbert-base-uncased'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_weight_dir = os.path.join(base_dir, distilbert_enc_name.split('/')[-1])\n",
    "os.makedirs(distilbert_weight_dir, exist_ok=True)\n",
    "distilbert_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd254a21-ba97-441e-bd4e-f9908a3f8d38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_enc = distilbert_enc.to(device)\n",
    "distilbert_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1176283d-3002-49a6-99a1-29d30bb0421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(distilbert_enc.embeddings.state_dict(), os.path.join(distilbert_weight_dir, 'distilbert_embeddings.pth'))\n",
    "\n",
    "for idx, layer in enumerate(distilbert_enc.transformer.layer):\n",
    "    torch.save(layer.state_dict(), os.path.join(distilbert_weight_dir, 'distilbert_layer_{}.pth'.format(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae368d09-6b0a-4c73-baeb-7d1653ddafd5",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8dec7-2b16-4261-9b73-bde52b553769",
   "metadata": {},
   "source": [
    "### google-bert/bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e35bc74-dc15-4031-89bb-2d2eb9728641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "bert_enc_name = 'google-bert/bert-base-uncased'\n",
    "bert_enc = BertModel.from_pretrained(bert_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f992c215-904d-438f-8bc8-601609fbcd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/bert-base-uncased'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_weight_dir = os.path.join(base_dir, bert_enc_name.split('/')[-1])\n",
    "os.makedirs(bert_weight_dir, exist_ok=True)\n",
    "bert_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e36f58ae-17b2-4fb1-ae20-fbaf4eab6814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_enc = bert_enc.to(device)\n",
    "bert_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e697b81-0170-4931-a12c-482015ff1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(bert_enc.embeddings.state_dict(), os.path.join(bert_weight_dir, 'bert_embeddings.pth'))\n",
    "\n",
    "for idx, layer in enumerate(bert_enc.encoder.layer):\n",
    "    torch.save(layer.state_dict(), os.path.join(bert_weight_dir, 'bert_layer_{}.pth'.format(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2efa8d-38b4-4de4-8517-e4766aac3206",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275c38a-268b-424e-bfb9-2e3683a8adef",
   "metadata": {},
   "source": [
    "### 'google/mobilebert-uncased' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35272bf6-2d2c-49d0-9da3-53ce4decee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MobileBertModel\n",
    "\n",
    "mobilebert_enc_name = 'google/mobilebert-uncased'\n",
    "mobilebert_enc = MobileBertModel.from_pretrained(mobilebert_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71d51ef8-3d65-4307-91d5-0dd285687a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/mobilebert-uncased'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilebert_weight_dir = os.path.join(base_dir, mobilebert_enc_name.split('/')[-1])\n",
    "os.makedirs(mobilebert_weight_dir, exist_ok=True)\n",
    "mobilebert_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec4c3b3-a5f2-4238-bf31-4c924a4d8ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertModel(\n",
       "  (embeddings): MobileBertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 512)\n",
       "    (token_type_embeddings): Embedding(2, 512)\n",
       "    (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "    (LayerNorm): NoNorm()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): MobileBertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): MobileBertLayer(\n",
       "        (attention): MobileBertAttention(\n",
       "          (self): MobileBertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): MobileBertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): MobileBertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): MobileBertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (bottleneck): OutputBottleneck(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (bottleneck): Bottleneck(\n",
       "          (input): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "          (attention): BottleneckLayer(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "          )\n",
       "        )\n",
       "        (ffn): ModuleList(\n",
       "          (0): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): FFNLayer(\n",
       "            (intermediate): MobileBertIntermediate(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (intermediate_act_fn): ReLU()\n",
       "            )\n",
       "            (output): FFNOutput(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): MobileBertPooler()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilebert_enc = mobilebert_enc.to(device)\n",
    "mobilebert_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a7d156-e27d-4960-ad28-419665597ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(mobilebert_enc.embeddings.state_dict(), os.path.join(mobilebert_weight_dir, 'mobilebert_embeddings.pth'))\n",
    "\n",
    "for idx, layer in enumerate(mobilebert_enc.encoder.layer):\n",
    "    torch.save(layer.state_dict(), os.path.join(mobilebert_weight_dir, 'mobilebert_layer_{}.pth'.format(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c336af-6ccd-452d-b7c3-bb14d5ad4689",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3dc315-c777-4f22-aebc-85983d112e37",
   "metadata": {},
   "source": [
    "### ast-finetuned-audioset-10-10-0.4593-finetuning-ESC-50-slower-LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2304f038-9ef3-49c0-b57f-b773dd2c0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ASTModel\n",
    "\n",
    "# ast_enc_name = 'xpariz10/ast-finetuned-audioset-10-10-0.4593-finetuning-ESC-50-slower-LR'\n",
    "ast_enc_name = 'MIT/ast-finetuned-audioset-10-10-0.4593'\n",
    "ast_enc = ASTModel.from_pretrained(ast_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cbc238-d0b5-4ce1-8b9f-a6e12ad146ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/ast-finetuned-audioset-10-10-0.4593'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast_weight_dir = os.path.join(base_dir, ast_enc_name.split('/')[-1])\n",
    "os.makedirs(ast_weight_dir, exist_ok=True)\n",
    "ast_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0fb71-1187-4ac4-879f-254209e4212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_enc = ast_enc.to(device)\n",
    "ast_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1888940-5887-40ee-bfee-70aa1621f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(ast_enc.embeddings.state_dict(), os.path.join(ast_weight_dir, 'ast_embeddings.pth'))\n",
    "\n",
    "for idx, layer in enumerate(ast_enc.encoder.layer):\n",
    "    torch.save(layer.state_dict(), os.path.join(ast_weight_dir, 'ast_layer_{}.pth'.format(idx)))\n",
    "\n",
    "torch.save(ast_enc.layernorm.state_dict(), os.path.join(ast_weight_dir, 'ast_layernorm.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cda8f9-8538-49b0-a158-d1a0cb7e1609",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee1f1d-bf0f-4188-a00e-4745d5055a6d",
   "metadata": {},
   "source": [
    "### bookbot/distil-ast-audioset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cde6f05-b016-4bde-b821-36b3fe9986aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ASTModel\n",
    "\n",
    "ast_enc_name = 'bookbot/distil-ast-audioset'\n",
    "ast_enc = ASTModel.from_pretrained(ast_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2e5fff-af66-4fd1-80ec-ee9893dace09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/distil-ast-audioset'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast_weight_dir = os.path.join(base_dir, ast_enc_name.split('/')[-1])\n",
    "os.makedirs(ast_weight_dir, exist_ok=True)\n",
    "ast_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d2b1df-7ba6-4b1a-937f-dca12f31ec30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTModel(\n",
       "  (embeddings): ASTEmbeddings(\n",
       "    (patch_embeddings): ASTPatchEmbeddings(\n",
       "      (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ASTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): ASTLayer(\n",
       "        (attention): ASTAttention(\n",
       "          (attention): ASTSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ASTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ASTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ASTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ASTLayer(\n",
       "        (attention): ASTAttention(\n",
       "          (attention): ASTSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ASTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ASTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ASTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ASTLayer(\n",
       "        (attention): ASTAttention(\n",
       "          (attention): ASTSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ASTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ASTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ASTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ASTLayer(\n",
       "        (attention): ASTAttention(\n",
       "          (attention): ASTSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ASTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ASTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ASTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ASTLayer(\n",
       "        (attention): ASTAttention(\n",
       "          (attention): ASTSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ASTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ASTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ASTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ASTLayer(\n",
       "        (attention): ASTAttention(\n",
       "          (attention): ASTSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ASTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ASTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ASTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast_enc = ast_enc.to(device)\n",
    "ast_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8d49f0-f660-43cf-aaa4-9641211c3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(ast_enc.embeddings.state_dict(), os.path.join(ast_weight_dir, 'ast_embeddings.pth'))\n",
    "\n",
    "for idx, layer in enumerate(ast_enc.encoder.layer):\n",
    "    torch.save(layer.state_dict(), os.path.join(ast_weight_dir, 'ast_layer_{}.pth'.format(idx)))\n",
    "\n",
    "torch.save(ast_enc.layernorm.state_dict(), os.path.join(ast_weight_dir, 'ast_layernorm.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad24ea-0da8-45e1-8419-fd43d11d7136",
   "metadata": {},
   "source": [
    "#### =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79561983-1e45-450f-87ef-b96b3c5c64ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2a96eea3334e718f8afd89fcd255da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import ASTModel\n",
    "\n",
    "ast_enc_name = 'MIT/ast-finetuned-audioset-10-10-0.4593'\n",
    "ast_enc = ASTModel.from_pretrained(ast_enc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ed252f-5907-436b-8526-34db7f9fedf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pretrained_weights/ast-finetuned-audioset-10-10-0.4593'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast_weight_dir = os.path.join(base_dir, ast_enc_name.split('/')[-1])\n",
    "os.makedirs(ast_weight_dir, exist_ok=True)\n",
    "ast_weight_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa73f62-2d79-4c41-9fdb-a255248e0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights seperately for later use.\n",
    "torch.save(ast_enc.embeddings.state_dict(), os.path.join(ast_weight_dir, 'ast_embeddings.pth'))\n",
    "\n",
    "for idx, layer in enumerate(ast_enc.encoder.layer):\n",
    "    torch.save(layer.state_dict(), os.path.join(ast_weight_dir, 'ast_layer_{}.pth'.format(idx)))\n",
    "\n",
    "torch.save(ast_enc.layernorm.state_dict(), os.path.join(ast_weight_dir, 'ast_layernorm.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123f32a-ade2-46f9-bcaf-bec44e333601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
